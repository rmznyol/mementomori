{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190b09bb",
   "metadata": {},
   "source": [
    "# Team *Memento Mori* - be mindful of death!\n",
    "\n",
    "In this project, we plan to analyze CDC Data to predict the likelihood of an individual dying from a natural cause or an unnatural cause."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e7991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a88b073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christiancofoid/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (40,41,42,43,61,62,63,64) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "## Import the data\n",
    "### Codes\n",
    "json2015 = pd.read_json('2015_codes.json')\n",
    "\n",
    "### Data -- a user might need to change the path if the data are stored somewhere else\n",
    "df2015 = pd.read_csv('2015_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a392c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take a sample from the data so that we aren't lugging around a 1.6gB array\n",
    "df_sample = df2015.sample(frac = 0.1, random_state = 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b0b284",
   "metadata": {},
   "source": [
    "List the columns of the DataFrame `df2015`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62eaa1d",
   "metadata": {},
   "source": [
    "## Natural/Unnatural encoding\n",
    "\n",
    "We now encode the deaths which we rule unnatural.  By an **unnatural death**, we mean a death which is caused by one of the following causes:\n",
    "1. Accident: \n",
    "    1. unintentional injuries\n",
    "    2. transportation\n",
    "    3. motor vehicle, land/water/air/space\n",
    "    4. nontransport accidents\n",
    "    5. Falls\n",
    "    6. Accidental discharge of firearms\n",
    "    7. Accidental drowning\n",
    "    8. Accidental exposure to smoke, fire, flames\n",
    "    9. Accidental poisoning\n",
    "2. Homicide:\n",
    "    1. Assault, not by the below causes\n",
    "    2. Assault with firearms\n",
    "    3. Assault with unspecified means\n",
    "3. Suicide:\n",
    "    1. Suicide by means other than the causes below\n",
    "    2. Suicide by discharge of firearm\n",
    "    3. Suidice by unspecified means\n",
    "4. Execution\n",
    "5. Undetermined intent\n",
    "    1. U.I. except those listed below\n",
    "    2. Discharge of firearms, undetermined intent\n",
    "    3. Other\n",
    "6. Operations of war\n",
    "7. Complications from medical and surgical care\n",
    "\n",
    "These correspond to cause of death codes 112-135 in the feature `113_cause_recode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b08c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain these codes from the 2015 json file\n",
    "causes_113 = json2015[json2015['113_cause_recode'].isnull() == False]['113_cause_recode']\n",
    "causes_113.index = list(map(int,causes_113.index))\n",
    "causes_113.name = '113_cause_recode_json'\n",
    "\n",
    "#extract unnatural causes labels\n",
    "unnatural_causes = causes_113.index[111:]\n",
    "# df_sample['113_cause_recode']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8344af1",
   "metadata": {},
   "source": [
    "Now label each instance as a natural -- $0$ -- or unnatural -- $1$ -- death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4914cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_label(row):\n",
    "    if row['113_cause_recode'] in unnatural_causes:\n",
    "        row['unnatural'] = 1\n",
    "    else:\n",
    "        row['unnatural'] = 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e3550",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.copy().apply(lambda x: class_label(x), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918539f",
   "metadata": {},
   "source": [
    "## `education`: cleaning the 1989_recoding problem\n",
    "\n",
    "In the feature `education_revision_2003` some of the instances are using a 1989 code, and these are the codes which are `nan` values.  Unstated education levels are encoded with a `99`.  The `nan` value in `education_revision_2003` is indicated with a 0 in the `education_reporting_flag` feature.  We use the feature `education_reporting_flag` to create a new feature, `education` which return the 2003 education revision and updates the instances which use the 1989 revision.  Values of `9`, which are unreported, are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def education_clean(row):\n",
    "    if row['education_reporting_flag'] == 0:\n",
    "        revis_1989 = row['education_1989_revision']\n",
    "        \n",
    "        # need to reclassify based on the 2003 education revision\n",
    "        if 0<= revis_1989 <= 8:\n",
    "            row['education'] = 1\n",
    "        elif 9<= revis_1989 <=11:\n",
    "            row['education'] = 2\n",
    "        elif revis_1989 == 12:\n",
    "            row['education'] = 3\n",
    "        elif revis_1989 == 13:\n",
    "            row['education'] = 4\n",
    "        elif 14<= revis_1989 <= 15:\n",
    "            row['education'] = 5\n",
    "        elif revis_1989 == 16:\n",
    "            row['education'] = 6\n",
    "        elif revis_1989 == 17: #some fudging is going on here -- not sure if >=5 years of college corresponds\n",
    "                                # to a Master's degree or PhD/Professional degree...\n",
    "            row['education'] = 7\n",
    "        elif revis_1989 == 99:\n",
    "            row['education'] = 9\n",
    "            \n",
    "    elif row['education_reporting_flag'] == 1:\n",
    "        row['education'] = int(row['education_2003_revision'])\n",
    "     \n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb6f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.apply(education_clean, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are missing about 4.5% of the education data -- use a simple imputer?\n",
    "df_sample[df_sample.education == 9].shape[0]/df_sample.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639285b3",
   "metadata": {},
   "source": [
    "Let us examine the distribution of the feature `education`, splitting into two plots based on `unnatural`.  \n",
    "- The feature `education` is an ordinal variable, since it measures the amount of formal education the decedent has received.\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0dfd65",
   "metadata": {},
   "source": [
    "## `age`\n",
    "There needs to be some cleaning of the data to determine the age of the decedent, particularly in the case of the death of an infant.  I'm not sure what's going on with the feature `detail_age` or if that has been condensed down to an integer representing number of years lived.  \n",
    "\n",
    "Note that ages which are missing are encoded as 999.  There aren't many, so we can just fill them with the median age for the particular value of `sex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45433e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.loc[df_sample.detail_age == 999].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439e7cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_med_age = df_sample[(df_sample.detail_age != 999) & (df_sample.sex == \"M\")].detail_age.median()\n",
    "F_med_age = df_sample[(df_sample.detail_age != 999) & (df_sample.sex == \"F\")].detail_age.median()\n",
    "def fill_missing_age(row):\n",
    "    if row['detail_age'] == 999:\n",
    "        if row['sex'] == 'M':\n",
    "            row['detail_age'] = M_med_age\n",
    "        if row['sex'] == 'F':\n",
    "            row['detail_age'] = F_med_age\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35da644",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_sample.copy().apply(fill_missing_age, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bbc2b",
   "metadata": {},
   "source": [
    "The number of instances when the age is recorded as 1, but the child died between the time of birth and the age of 1 is tiny compared to the number of observations: about $0.25\\%$ of the instances correspond to this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91921d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.detail_age.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d09893",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (8,4))\n",
    "\n",
    "#first plot is of the age distribution of natural deaths\n",
    "# drop the values of 999, which are missing\n",
    "sns.histplot(data = df_sample[(df_sample.detail_age != 999)&(df_sample.unnatural == 0)],\n",
    "            x = 'detail_age',\n",
    "            ax = ax[0],\n",
    "            hue = 'sex',\n",
    "             stat = 'probability',\n",
    "             hue_order = ['F','M'],\n",
    "            bins = np.arange(1,df_sample.detail_age[df_sample.detail_age < 999].max()))\n",
    "ax[0].set_title('Age of natural deaths,\\ncolored by sex of decedent')\n",
    "ax[0].set_xticks(range(0,115,10))\n",
    "\n",
    "#second plot is of the age distribution of unnatural deaths\n",
    "# drop the values of 999, which are missing\n",
    "sns.histplot(data = df_sample[(df_sample.detail_age != 999)&(df_sample.unnatural == 1)],\n",
    "            x = 'detail_age',\n",
    "            ax = ax[1],\n",
    "            hue = 'sex',\n",
    "             stat = 'probability',\n",
    "             hue_order = [\"F\",\"M\"],\n",
    "            bins = np.arange(1,df_sample.detail_age[df_sample.detail_age < 999].max()))\n",
    "ax[1].set_title('Age of unnatural deaths,\\ncolored by sex of decedent')\n",
    "ax[1].set_xticks(range(0,115,10))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7227a7e7",
   "metadata": {},
   "source": [
    "Note the difference in the $y$-scales.\n",
    "\n",
    "It looks like there is a considerable difference in the distribution of `detailed_age` based on whether or not the death was natural.  Moreover, the `sex` of the decedent changes the distribution of the age unnatural deaths considerably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f23c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (8,4))\n",
    "\n",
    "#first plot is of the age distribution of natural deaths\n",
    "sns.histplot(data = df_sample[(df_sample.unnatural == 0)],\n",
    "            x = 'detail_age',\n",
    "            ax = ax[0],\n",
    "            hue = 'marital_status',\n",
    "             hue_order = ['W','M','S','D','U'],\n",
    "             stat = 'probability',\n",
    "            bins = np.arange(1,df_sample.detail_age.max()))\n",
    "ax[0].set_title('Age of natural deaths,\\ncolored by matrial status of decedent')\n",
    "ax[0].set_xticks(range(0,115,10))\n",
    "\n",
    "#second plot is of the age distribution of unnatural deaths\n",
    "sns.histplot(data = df_sample[(df_sample.unnatural == 1)],\n",
    "            x = 'detail_age',\n",
    "            ax = ax[1],\n",
    "            hue = 'marital_status',\n",
    "             hue_order = ['W','M','S','D','U'],\n",
    "             stat = 'probability',\n",
    "            bins = np.arange(1,df_sample.detail_age.max()))\n",
    "ax[1].set_title('Age of unnatural deaths,\\ncolored by marital status of decedent')\n",
    "ax[1].set_xticks(range(0,115,10))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95ce685",
   "metadata": {},
   "source": [
    "Natural deaths occur more frequently later in life for married decedents (M) or widow/widower decedents (W).  Single decedents (S) have a much higher probability of dying due to an unnatural than a natural cause at an early age.  It is interesting to note that the distribution of age for married decedents from unnatural causes looks quite symmetric, as does the distribution for divorced due to unnatural causes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4e921b",
   "metadata": {},
   "source": [
    "## `manner_of_death`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e33f2b8",
   "metadata": {},
   "source": [
    "## `race`\n",
    "\n",
    "Do some aggregation on `df_sample` to compute probability of unnatural death for each race."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b12391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dct = {key: val for key, val in zip(sorted(df_sample.race.unique()),\n",
    "    [\"White\",\"Black\", \"American Indian\", \"Chinese\",\n",
    "     \"Japanese\", \"Hawaiian\", \"Filipino\",\"Asian Indian\",\n",
    "     \"Korean\", \"Samoan\", \"Vietnamese\", \"Guamanian\",\n",
    "     \"Other Asian\\nor P.I.\",\"Combined \\no. Asian or P.I.\"])}\n",
    "\n",
    "unnat_by_race = df_sample.groupby('race').agg({\"unnatural\":[np.sum, len]})['unnatural']\n",
    "unnat_by_race.loc[:,\"cond_rel_freq\"]= unnat_by_race['sum']/unnat_by_race['len']\n",
    "def assign_race(row):\n",
    "    row['Race'] = race_dct[row.name]\n",
    "    return row\n",
    "unnat_by_race = unnat_by_race.copy().apply(assign_race, axis = 1)\n",
    "unnat_by_race.columns = ['unnatural_deaths','total_deaths', 'cond_rel_freq','race']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3e0b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnat_by_race"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90104b4b",
   "metadata": {},
   "source": [
    "Let $R$ be the random variable indicating a decedent's race, and $U$ be the random variable indicating the type of death (unnatural = 1, natural = 0).  We plot the distribution $P(U = 1|R = r)$ for each race $r\\in \\mathtt{race\\underline{\\,\\,\\,}dct.values}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961549d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2,1,figsize = (8,8))\n",
    "\n",
    "ax[0].bar(x = unnat_by_race.race,\n",
    "      height= unnat_by_race.cond_rel_freq,\n",
    "      alpha = 0.7)\n",
    "ax[0].set_ylabel('$P(U = 1|R = r)$')\n",
    "ax[0].set_xticklabels(unnat_by_race.race, rotation = 70)\n",
    "ax[0].set_title('Probability of unnatural death, by race')\n",
    "\n",
    "ax[1].bar(x = unnat_by_race.race,\n",
    "          height = np.log10(unnat_by_race.total_deaths),\n",
    "          alpha = 0.7\n",
    "         )\n",
    "ax[1].set_ylabel('$\\log(\\mathtt{count})$')\n",
    "ax[1].set_xticklabels(unnat_by_race.race, rotation = 70)\n",
    "ax[1].set_title('Log deaths by unnatural causes, by race')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a713fc0",
   "metadata": {},
   "source": [
    "# Trying to predict `unnatural`: plot things with this as hue\n",
    "\n",
    "## Features to do EDA on: `detail_age`, `marital_status`, `education`, `sex`, `resident_status`, `race`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317b784",
   "metadata": {},
   "source": [
    "### `detail_age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (6,4))\n",
    "\n",
    "sns.histplot(data = df_sample,\n",
    "            x = 'detail_age',\n",
    "            hue = 'unnatural',\n",
    "            stat='probability', \n",
    "            kde = True);\n",
    "ax.set_xlabel('decedent age $x$', fontsize = 14)\n",
    "ax.set_ylabel('probability of decedent\\ndying at age $x$', fontsize = 14)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Patch\n",
    "fig, ax = plt.subplots(1,1,figsize = (6,4))\n",
    "\n",
    "sns.boxenplot(x=\"detail_age\", y=\"unnatural\", \n",
    "            data=df_sample, orient=\"h\",\n",
    "            palette={1:\"red\", 0:\"blue\"}, ax=ax,)\n",
    "\n",
    "color_patches = [\n",
    "    Patch(facecolor=\"red\", label=\"unnatural\"),\n",
    "    Patch(facecolor=\"blue\", label=\"natural\")]\n",
    "    \n",
    "ax.set_ylabel('')\n",
    "ax.legend(handles = color_patches);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e580241e",
   "metadata": {},
   "source": [
    "#### Conclusions:\n",
    "1. Different means and different skewness\n",
    "2. Many outliers for the `unnatural = 0` group.\n",
    "3. This makes sense -- natural deaths tend to happen later in life, while there are certainly outliers which happen early, due to childhood/adolescent disease, as well as disease in early adulthood.  Unnatural deaths are more likely to occur when a person is out in the world exposed to danger -- this more frequently happens to middle-aged adults as they go about their business and work.\n",
    "\n",
    "\n",
    "A printout of the summary statistics of the distribution of `detail_age`, by `unnatural`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597068eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_group = df_sample.groupby('unnatural')\n",
    "\n",
    "def quantile(x,q):\n",
    "    return np.quantile(x,q)\n",
    "age_group_agg = age_group.agg({\"detail_age\":[(\"mean\",np.mean),\n",
    "                             (\"min\",np.min), \n",
    "                             (\"q_25\",lambda x: quantile(x,0.25)),\n",
    "                             ('median',np.median), \n",
    "                             (\"q_75\",lambda x: quantile(x,0.75)),\n",
    "                             ('max',np.max), ]})['detail_age']\n",
    "print('Summary of the feature detail_age, by unnatural:')\n",
    "print('====================================================')\n",
    "print(age_group_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8dfb90",
   "metadata": {},
   "source": [
    "### `education`\n",
    "\n",
    "The variable `education_2003_recode` has been cleaned up and is in the variable `education`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (6,4))\n",
    "\n",
    "sns.histplot(data = df_sample,\n",
    "            x = 'education',\n",
    "            hue = 'unnatural',\n",
    "#             stat = 'probability',\n",
    "            bins = np.arange(1,10)-0.5\n",
    "            );\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cacffa4",
   "metadata": {},
   "source": [
    "Unnatural deaths increase as education level increases until a person has completed high-school or obtained a GED, then they began to decrease after completing some college.  \n",
    "\n",
    "For natural deaths, there is a slight decrease from pre-high school to some high-school, but this can be explained by variable `detail_age`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12264e4b",
   "metadata": {},
   "source": [
    "### `marital_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00ed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (6,4))\n",
    "\n",
    "sns.histplot(data = df_sample,\n",
    "            x = 'marital_status',\n",
    "            hue = 'unnatural',\n",
    "#             stat = 'probability',\n",
    "#             bins = np.arange(1,10)-0.5\n",
    "            );\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10,6))\n",
    "\n",
    "#first plot is of the age distribution of natural deaths\n",
    "sns.histplot(data = df_sample[(df_sample.unnatural == 0)],\n",
    "            x = 'detail_age',\n",
    "            ax = ax[0],\n",
    "            hue = 'marital_status',\n",
    "             hue_order = ['W','M','S','D','U'],\n",
    "             stat = 'probability',\n",
    "            bins = np.arange(1,df_sample.detail_age.max()))\n",
    "ax[0].set_title('Age of natural deaths,\\ncolored by matrial status of decedent')\n",
    "ax[0].set_xticks(range(0,115,10))\n",
    "\n",
    "#second plot is of the age distribution of unnatural deaths\n",
    "sns.histplot(data = df_sample[(df_sample.unnatural == 1)],\n",
    "            x = 'detail_age',\n",
    "            ax = ax[1],\n",
    "            hue = 'marital_status',\n",
    "             hue_order = ['W','M','S','D','U'],\n",
    "             stat = 'probability',\n",
    "            bins = np.arange(1,df_sample.detail_age.max()))\n",
    "ax[1].set_title('Age of unnatural deaths,\\ncolored by marital status of decedent')\n",
    "ax[1].set_xticks(range(0,115,10))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183af95",
   "metadata": {},
   "source": [
    "### `resident_status`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4faebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize = (6,4))\n",
    "\n",
    "sns.histplot(data = df_sample,\n",
    "            x = 'resident_status',\n",
    "            hue = 'unnatural',\n",
    "#             stat = 'probability',\n",
    "             bins = [1,2,3,4,5]\n",
    "            );\n",
    "ax.set_xticks([i + 0.5 for i in range(1,5)])\n",
    "ax.set_xticklabels([i for i in range(1,5)])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5245f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample.resident_status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829d87c3",
   "metadata": {},
   "source": [
    "# Checking Ramazan's work:\n",
    "Ramazan used the features `['education_2003_revision', 'month_of_death', 'age_recode_52', 'detail_age', 'day_of_week_of_death', 'activity_code']`, but I am going to replace `education_2003_revision` with the cleaned education feature `education`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21e1580",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_to_use = ['education',\n",
    " 'month_of_death',\n",
    "#  'age_recode_52',\n",
    " 'detail_age',\n",
    " 'day_of_week_of_death',\n",
    " 'activity_code', 'marital_status',\n",
    "               'sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d280de",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in feats_to_use:\n",
    "    print(\"Unique features of {}:{} \".format(x,sorted(df_sample[x].unique())))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f995c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a custom transformer to code the features marital_status and sex\n",
    "# as well as scale the detail_age\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.StandardScaler = StandardScaler() #to scale the detail_age of decedent\n",
    "        self.OneHotEncoderMS = OneHotEncoder() #to encode marital_status of decedent\n",
    "        self.OneHotEncoderSex = OneHotEncoder() #to encode sex of decedent\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        #fit the StandardScaler for detail_age of decedent\n",
    "        self.StandardScaler.fit(X[['detail_age']])\n",
    "        \n",
    "        #fit the onehot for marital_status of decedent\n",
    "        self.OneHotEncoderMS.fit(X[['marital_status']])\n",
    "        \n",
    "        #fit the onehot for sex of decedent\n",
    "        self.OneHotEncoderSex.fit(X[['sex']])\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y = None):\n",
    "        copy_X = X.copy()\n",
    "        \n",
    "        #scale detail_age of decedent\n",
    "        copy_X['detail_age'] = self.StandardScaler.transform(copy_X[['detail_age']])\n",
    "        \n",
    "        #encode marital_status of decedent\n",
    "        ms_encoded = pd.DataFrame(self.OneHotEncoderMS.transform(copy_X[['marital_status']]).toarray(),\n",
    "                               columns = self.OneHotEncoderMS.categories_[0],\n",
    "                                 index = copy_X.index)\n",
    "        \n",
    "        #encode sex of decedent, removing one column (sex_M = 1-sex_F)\n",
    "        sex_encoded = pd.DataFrame(self.OneHotEncoderSex.transform(copy_X[['sex']]).toarray(),\n",
    "                               columns = [\"sex_{}\".format(x) for x in self.OneHotEncoderSex.categories_[0]],\n",
    "                                  index = copy_X.index)\n",
    "        sex_encoded = sex_encoded.copy()[['sex_M']]\n",
    "#         print((sex_encoded.index != ms_encoded.index).sum())\n",
    "        \n",
    "        #now merge the two encoded dataframes from above\n",
    "        copy_X = copy_X.join([ms_encoded, sex_encoded])\n",
    "        \n",
    "        return copy_X\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0b47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb607d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a train_test_split to df_sample\n",
    "train, test = train_test_split(df_sample, test_size = 0.2, \n",
    "                              random_state = 1907, \n",
    "                              shuffle = True,\n",
    "                              stratify = df_sample.unnatural)\n",
    "\n",
    "#Now transform the ***training*** data\n",
    "data_transformer = CustomTransformer()\n",
    "data_transformer.fit(train)\n",
    "train = data_transformer.transform(train.copy())\n",
    "\n",
    "#And transform the test data\n",
    "test = data_transformer.transform(test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018936c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import recall_score, f1_score, confusion_matrix, classification_report, roc_curve\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac309576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "updated_ftu = ['education',\n",
    "              'month_of_death',\n",
    "              #  'age_recode_52',\n",
    "              'detail_age',\n",
    "              'day_of_week_of_death',\n",
    "              #'activity_code',\n",
    "               'D', 'M', 'S', 'U', 'W', 'sex_M']\n",
    "\n",
    "n_splits = 10\n",
    "n_models = 5\n",
    "kfold = StratifiedKFold(n_splits = n_splits,\n",
    "                        shuffle = True, \n",
    "                        random_state = 1907)\n",
    "#axis 0: index of the kfold \n",
    "#axis 1: for the score type: recall, f1\n",
    "#axis 2: for the model number\n",
    "results = np.zeros((n_splits, 2, n_models))\n",
    "\n",
    "#might use this, but probably not.\n",
    "model_lst = [LogisticRegression(max_iter = 10000),\n",
    "            LogisticRegression(max_iter = 10000, class_weight = 'balanced'),\n",
    "            RandomForestClassifier(n_estimators = 100, max_depth = 8),\n",
    "            RandomForestClassifier(n_estimators=100, max_depth=8 ,class_weight = 'balanced')]\n",
    "\n",
    "i = 0\n",
    "for tt_ix, ho_ix in kfold.split(train, train.unnatural):\n",
    "    \n",
    "    #make the train and holdhout sets\n",
    "    train_tt, train_ho = train.iloc[tt_ix], train.iloc[ho_ix]\n",
    "    \n",
    "    #fit the five models\n",
    "    \n",
    "    #Model 0: Classify as all zeros\n",
    "    all_zeros = np.zeros(train_ho.unnatural.shape[0])\n",
    "    results[i,0,0] = f1_score(all_zeros, train_ho.unnatural, zero_division = 0)\n",
    "    results[i,1,0] = recall_score(all_zeros, train_ho.unnatural, zero_division = 0)\n",
    "    print(f'Model 0 {i}th validation \\n', \n",
    "          classification_report(train_ho['unnatural'].values,\n",
    "                                all_zeros),'\\n')\n",
    "    \n",
    "    #Model 1: Logistic Regression: no weights\n",
    "    lr1 = LogisticRegression(max_iter = 10000)\n",
    "    lr1.fit(train_tt[updated_ftu], train_tt.unnatural)\n",
    "    lr1_pred = lr1.predict(train_ho[updated_ftu])\n",
    "    results[i,0,1] = f1_score(lr1_pred, train_ho.unnatural)\n",
    "    results[i,1,1] = recall_score(lr1_pred, train_ho.unnatural)\n",
    "    print(f'Model 1 {i}th validation \\n', \n",
    "          classification_report(train_ho['unnatural'].values,\n",
    "                                lr1_pred),'\\n')\n",
    "    \n",
    "    #Model 2: Logistic Regressin: weights\n",
    "    lr2 = LogisticRegression(class_weight = 'balanced')\n",
    "    lr2.fit(train_tt[updated_ftu],train_tt.unnatural)\n",
    "    lr2_pred = lr2.predict(train_ho[updated_ftu])\n",
    "    results[i,0,2] = f1_score(lr2_pred, train_ho.unnatural)\n",
    "    results[i,1,2] = recall_score(lr2_pred, train_ho.unnatural)\n",
    "    print(f'Model 2 {i}th validation \\n', \n",
    "          classification_report(train_ho['unnatural'].values,\n",
    "                                lr2_pred),'\\n')\n",
    "    \n",
    "    \n",
    "    #Model 3: Random Forest: no weights\n",
    "    rf1 = RandomForestClassifier()\n",
    "    rf1.fit(train_tt[updated_ftu],train_tt.unnatural)\n",
    "    rf1_pred = rf1.predict(train_ho[updated_ftu])\n",
    "    results[i,0,3] = f1_score(rf1_pred, train_ho.unnatural)\n",
    "    results[i,1,3] = recall_score(rf1_pred, train_ho.unnatural)\n",
    "    print(f'Model 3 {i}th validation \\n', \n",
    "          classification_report(train_ho['unnatural'].values,\n",
    "                    rf1_pred),'\\n')\n",
    "    print(rf1.feature_importances_)\n",
    "    \n",
    "    #Model 4: Random Forest: weights\n",
    "    rf2 = RandomForestClassifier(class_weight='balanced')\n",
    "    rf2.fit(train_tt[updated_ftu],train_tt.unnatural)\n",
    "    rf2_pred = rf2.predict(train_ho[updated_ftu])\n",
    "    results[i,0,4] = f1_score(rf2_pred, train_ho.unnatural)\n",
    "    results[i,1,4] = recall_score(rf2_pred, train_ho.unnatural)\n",
    "    print(f'Model 4 {i}th validation \\n', \n",
    "          classification_report(train_ho['unnatural'].values,\n",
    "                                rf2_pred),'\\n')\n",
    "    print(rf2.feature_importances_)\n",
    "    \n",
    "    \n",
    "    #Model 5\n",
    "    \n",
    "    \n",
    "    i+= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbfb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.mean(axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dcc3ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
